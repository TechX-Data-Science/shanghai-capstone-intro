{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q4sk8FtwjV_Y"
   },
   "source": [
    "# 0. Overview\n",
    "- Dataset: https://www.kaggle.com/c/titanic/overview\n",
    "- Reference: https://www.kaggle.com/rbud613/taitanic-eda/comments#846113\n",
    "- Pre-requisite:\n",
    "    - Knowledge of numpy and Python pandas;\n",
    "    - Knowledge of machine learning concepts;\n",
    "    - Passion to learn;\n",
    "    - Ready to ask question (to both Google and your Tech Lead).\n",
    "- Objective:\n",
    "    - Understanding the basic ML model building procedure (for classification problem).\n",
    "\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v2hk1qJaxf1x"
   },
   "source": [
    "# 1. Get Started\n",
    "- **Overview**: 在这个部分，你将【读取】这个项目需要的数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DzuofEuOysG7"
   },
   "source": [
    "## 1.1. Getting the Data\n",
    "- 首先，我们来看看我们要处理的数据长什么样\n",
    "- 如你们所见，这个数据集包括了许多 Titanic 乘客的信息\n",
    "- 这个部分有 **1 个 TODO** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "msLtPBQ-jE1_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8zeyMIri5jCU"
   },
   "source": [
    "**TODO 1.1:** Use pandas libary to read in the data we need (i.e. train.csv & test.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oUrtdcN7yj7w"
   },
   "outputs": [],
   "source": [
    "# Your Code Starts Here\n",
    "train = ...\n",
    "test = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VVgiK1mIxP-2",
    "outputId": "9421ad69-aa71-43cd-ee53-fec15a5a2f2d"
   },
   "outputs": [],
   "source": [
    "# First few lines of training set (i.e. the data WITH known labels)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lRDaBdrExQFG",
    "outputId": "d75f03b2-5f18-4c58-cfa9-b5ed1ced8b4f"
   },
   "outputs": [],
   "source": [
    "# First few lines of test set (i.e. the data WITHOUT known labels)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M2eb7Tbr0LjV"
   },
   "source": [
    "![Data Dictionary](./data/data_dictionary.png)\n",
    "\n",
    "\n",
    "- 变量名 (aka passenger info)\n",
    "    - pclass: 仓位等级\n",
    "        - 1st = Upper\n",
    "        - 2nd = Middle\n",
    "        - 3rd = Lower\n",
    "\n",
    "    - age: 年龄。Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
    "\n",
    "    - sibsp: 同辈亲人（兄弟姐妹、配偶）。The dataset defines family relations in this way...\n",
    "        - Sibling = brother, sister, stepbrother, stepsister\n",
    "        - Spouse = husband, wife (mistresses and fiancés were ignored)\n",
    "\n",
    "    - parch: 非同辈亲人（子女、父母）。The dataset defines family relations in this way...\n",
    "        - Parent = mother, father\n",
    "        - Child = daughter, son, stepdaughter, stepson\n",
    "        - Some children travelled only with a nanny, therefore parch=0 for them.\n",
    "\n",
    "- **Take a few minutes to look at the dataset and get an idea of it**\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O4c-QZELyBnt"
   },
   "source": [
    "# 2. Prediction\n",
    "## 2.0 概述\n",
    "- 在这个部分，我们会进行这个项目的核心环节：通过乘客们的信息来预测他们是否会在 titanic 沉船案中生存下来。\n",
    "- 这个部分有 **1 个 TODO**\n",
    "\n",
    "- 数据已经被分成了两部分：\n",
    "  - 训练集 (data/train.csv)\n",
    "  - 测试集 (data/test.csv)\n",
    "\n",
    "- **训练集**将用来训练机器学习模型，因此我们将提供**真实**的分类答案（i.e. label），也就是说，对于训练集中的每一位乘客，我们都将有他们**是否存活**的数据 (在**Survived**那一列)\n",
    "\n",
    "- **测试集**将用来测试我们的模型。因此我们**没有提供**真实的分类答案（i.e. label）。你在这个部分的主要工作就是用你训练出来的模型来预测每个乘客是否会在这场灾难里活下来。\n",
    "\n",
    "- **最终提交**的结果需要遵循`gender_submission.csv`这个表格的格式。It is a set of predictions that **assume** all and only female passengers survive, as an example of what a submission file should look like.\n",
    "\n",
    "`References`: \n",
    "- 1. https://www.kaggle.com/c/titanic/overview\n",
    "- 2. https://www.kaggle.com/ash316/eda-to-prediction-dietanic\n",
    "\n",
    "`Submission to:` https://www.kaggle.com/c/titanic/submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "RxdFpvZ4xQJS",
    "outputId": "91ecb7dc-5e59-4d17-f7ca-5284681be45d"
   },
   "outputs": [],
   "source": [
    "# Example of final submission file - this is the kind of file you want to output at the end of the project\n",
    "pd.read_csv('data/gender_submission.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8gqJjjRXeMVj"
   },
   "source": [
    "**TODO 2.0** \n",
    "- 1. 读取 train 和 test 两个表格（使用 Pandas）\n",
    "- 2. 在 train 和 test 这两个表格中都加入一列 'dataset' 用于表示他们所属于的数据集\n",
    "- 3. 将这两个表格合并到一起（使用 pd.concat）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "id": "1PGUg4hDd1_x",
    "outputId": "821ccb66-eda9-4450-aca6-440420e54f4f"
   },
   "outputs": [],
   "source": [
    "# step 1 读取 train 和 test 两个表格（使用 Pandas）\n",
    "train = ...\n",
    "test = ...\n",
    "\n",
    "# step 2 在 train 和 test 这两个表格中都加入一列 'dataset' 用于表示他们所属于的数据集\n",
    "\n",
    "\n",
    "# step 3 将这两个表格合并到一起（使用 pd.concat）\n",
    "data = ...\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wfABcIv6Mblw"
   },
   "source": [
    "## 2.1 Feature Understanding\n",
    "- 在这个部分，我们将研究一下各个特征之间的联系，这将给我们的特征选择提供一定有价值的参考。\n",
    "- 这个部分**没有 TODO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RepuN6KqNB8k"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 534
    },
    "colab_type": "code",
    "id": "MsoGFEv9MqDk",
    "outputId": "193666cc-4d73-408c-a342-427c6404891a"
   },
   "outputs": [],
   "source": [
    "sns.heatmap(data.corr(), annot = True, cmap = 'RdYlGn' , linewidths = 0.2) # data.corr() --> correlation matrix\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10, 8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lx93PRnzMB9K"
   },
   "source": [
    "## 2.2. Feature Engineering & Pre-processing\n",
    "- 在这个部分，我们将进行这个 Pipeline 中的第二步：**特征工程**。这也是传统机器学习中最重要的部分 —— 因为这一部分中构造的特征将**直接决定**模型的表现。\n",
    "- 特征工程的常用技巧有如下几种\n",
    "    - **Imputation 填补**: 处理缺失数值\n",
    "    - **Binning 分区**: 将一些数值划分到某些\n",
    "    - **Feature Split&Combination 合并/分割特征**: 分割/合并某些特征\n",
    "    - **One-Hot Encoding**: encode catogerical data\n",
    "    - **Pipeline 管道**: 将多个特征处理合并到一起处理\n",
    "- However, since Titanic dataset is somewhat simple, I would suggest the following [artical](https://towardsdatascience.com/feature-engineering-for-machine-learning-3a5e293a5114) where feature engineering is better summarized. \n",
    "- 在这个部分有 **7 个 TODO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F1K3xhFy-S5L"
   },
   "source": [
    "### 2.2.1 Initials / Ages (Imputation/填补)\n",
    "- The first thing we'd like to investigate is whether age could decide one's survival\n",
    "- If you remember, there are lots of `nan` in the `Age` column, in order to fill those blanks with appropriate age, what we will do is to find the initial of every person and find the average age for each initial.\n",
    "- Then we will fill those `nan` in `Age` column with average age of that initial. (**Think about this, does this make sense?**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先看看 age 列有多少 NaN\n",
    "data.Age.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fciSuNwb-S5L",
    "outputId": "4c597a07-1b1c-4f3d-c625-70b8ecbda67e"
   },
   "outputs": [],
   "source": [
    "import re # Use regular expression（正则表达式）\n",
    "\n",
    "# Do Not modify this cell, just run it.\n",
    "data['initial'] = data.Name.apply(lambda s: re.findall(r'([A-Za-z]+)\\.', s)[0]) \n",
    "data[['Name', 'initial']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "49XESnXm-S5M"
   },
   "source": [
    "- For more information about the use of regular expression, here is a useful link: [Python regular expression](https://www.tutorialspoint.com/python/python_reg_expressions.htm)\n",
    "- **It is not required for you to know regular expression for this project, but it's encouraged to learn it on your own (it takes a while to understand it!).**\n",
    "\n",
    "- Now, take a look at our results of initials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ziFHoWGw-S5M",
    "outputId": "2f94c6b7-3868-4c4e-cad0-2a95775152a8"
   },
   "outputs": [],
   "source": [
    "# As you can see here, there is too many unique initials, \n",
    "# while some of them could be manually classified into the same one \n",
    "data.initial.unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TkbX4nUI-S5N"
   },
   "outputs": [],
   "source": [
    "# DO NOT modify this cell, just run it (try to understand the use of pd.replace() function!)\n",
    "data.initial = data.initial.replace(\n",
    "    ['Mlle','Mme','Ms','Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don', 'Dona'],\n",
    "    ['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr', 'Miss']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vo4T6-uc-S5O",
    "outputId": "265074ea-d37e-4edb-ed2f-7ce44eb92097"
   },
   "outputs": [],
   "source": [
    "data.initial.unique() # Looks good now!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DqiKyR1o-S5P"
   },
   "source": [
    "**TODO 2.1:** 对于每个 initial 组，计算平均年龄，然后将所有`nan`的地方填上 ta 所在年龄组的平均年龄\n",
    "- Hint: make use of `pd.groupby()` function, [link to doc](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html)\n",
    "- Hint: make use of `pd.fillna()` function, [link to doc](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ia9WWgOo-S5Q"
   },
   "outputs": [],
   "source": [
    "# Your Code Starts Here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "73EL2iW6-S5R"
   },
   "outputs": [],
   "source": [
    "# Your Code Starts Here\n",
    "data.loc[(data.Age.isnull()) & (data.initial == 'Mr'), 'Age'] = 33\n",
    "data.loc[(data.Age.isnull()) & (data.initial == 'Mrs'), 'Age'] = ...\n",
    "data.loc[(data.Age.isnull()) & (data.initial == 'Master'), 'Age'] = ...\n",
    "data.loc[(data.Age.isnull()) & (data.initial == 'Miss'), 'Age'] = ...\n",
    "data.loc[(data.Age.isnull()) & (data.initial == 'Other'), 'Age'] = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gvx39HTiQjfS"
   },
   "source": [
    "### 2.2.2 Age band (Binning/分区)\n",
    "- 在这个部分，我们会将年龄分为 5 个类，这样做有助于将一个复杂的 feature 变成一个简单的 feature\n",
    "- **TODO 2.2:** Implement the function `handle_age_band` and apply it to the train dataframe. Hint: use `pd.apply()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-tGexSSWyFZT"
   },
   "outputs": [],
   "source": [
    "# Function to handle age band implementation\n",
    "# [0-16]: 0\n",
    "# [17-32]: 1\n",
    "# [33-48]: 2\n",
    "# [49-64]: 3\n",
    "# [>64]: 4\n",
    "def handle_age_band(age):\n",
    "    if age <= 16:\n",
    "        return 0\n",
    "    # Your Code Starts Here  \n",
    "    return -1 # Modify here\n",
    "    # Your Code Ends Here\n",
    "\n",
    "\n",
    "# Your Code Starts Here\n",
    "data['age_band'] = ...\n",
    "# Your Code Ends Here\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Ps1nXFuRDKV"
   },
   "source": [
    "### 2.2.3 Family Size (Feature Combination)\n",
    "- we would also like to investigate whether family size have an impact on passenger's survival\n",
    "\n",
    "- **TODO 2.3:** Here we create a new feature called `family_size` which is the sum of `Parch` and `SibSp` columns for each row; also, create another column called `alone` where 1 means traveling without families and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qJtzTjRNyFcc"
   },
   "outputs": [],
   "source": [
    "# Your Code Starts Here\n",
    "data['family_size'] = ...\n",
    "data['alone'] = ... # hint: make use of pd.apply() function on family_size column\n",
    "# Your Code Ends Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "70q_hAXgi47y"
   },
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kvJM1Rb6j45C"
   },
   "source": [
    "### 2.2.4 Checking null values again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "ZH_uhJFJj5ND",
    "outputId": "28c36621-2007-460d-b7fc-9f679e1e7408",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s1BCVVdVnHHr"
   },
   "source": [
    "- **TODO 2.4:** 把数据集里的其他 NaN 数值进行填充\n",
    "- Hint: make use of `pd.fillna()` function, [link to doc](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JJSoRvovj524"
   },
   "outputs": [],
   "source": [
    "# Examples\n",
    "data.Embarked = data.Embarked.fillna('S') # Because 'S' is the most common embark (登船) location.\n",
    "\n",
    "# TODO: handle other null values, if there is any; if not, just ignore it\n",
    "# Note: if there is null in the 'Survived' column, it's fine.\n",
    "\n",
    "# Your Code Starts Here\n",
    "fare_median = ...\n",
    "data.Fare = data.Fare.fillna(fare_median) # Fill the nan values in fare columns with median value of passenger fare.\n",
    "# Your Code Ends Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iaOE5axKj5yG"
   },
   "outputs": [],
   "source": [
    "# Drop un-needed features\n",
    "data = data.drop(columns = ['Name', 'Ticket', 'PassengerId', 'Cabin', 'Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vXU4Otd8-S5d"
   },
   "source": [
    "### 2.2.5 One-hot Encoding\n",
    "- In this section, we will look at another important feature engineering process, specially designed for categorical data: **One-hot Encoding**.\n",
    "- The idea behind one-hot encoding is simple: instead of using categorical labels, we use several seperate columns for each label (see example below).\n",
    "- Through one-hot encoding, we could tramsfrom data from some format that the model couldn't take as an input(text, image, etc) into vectors that the model could calculate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Wzxk-2G-S5d",
    "outputId": "f61859cf-049d-4381-e49c-d90a427fe22d"
   },
   "outputs": [],
   "source": [
    "# Original data\n",
    "original = pd.DataFrame({\n",
    "    'name': ['Joey', 'Scott', 'Jasmine', 'Alan', 'Mao'],\n",
    "    'Major': ['DataSci', 'DataSci', 'CogsSci', 'DataSci', 'CompSci']\n",
    "})\n",
    "onehot = pd.DataFrame({\n",
    "    'name': ['Joey', 'Scott', 'Jasmine', 'Alan', 'Mao'],\n",
    "    'DataSci': [1, 1, 0, 1, 0],\n",
    "    'CogsSci': [0, 0, 1, 0, 0],\n",
    "    'CompSci': [0, 0, 0, 0, 1]\n",
    "})\n",
    "\n",
    "display(original, onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JhCG7Lws-S5e"
   },
   "source": [
    "- The way to achieve these encoded features is simple: Sci-kit Learn already has package for this:\n",
    "    - [One-hot Encoder from Scikit](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)\n",
    "    - **Note**: the output for this transformer is a matrix, which is kind of hard to debug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rgFNJO4U-S5e"
   },
   "outputs": [],
   "source": [
    "# This is a quick way of \"query\" into the dataframe, like a SQL query. \n",
    "train_df = data.query('dataset == \"Train\"').drop(columns = ['dataset'])\n",
    "\n",
    "# We don't need survived column for test set.\n",
    "test_df = data.query('dataset == \"Test\"').drop(columns = ['Survived', 'dataset']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f79bNMrW-S5h"
   },
   "outputs": [],
   "source": [
    "X_train, y_train = train_df.drop(columns = ['Survived']), train_df.Survived.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m8Vv9QdK-S5i"
   },
   "source": [
    "- **TODO 2.5:** 对 initial 这一列进行 one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CD_ZdGPi-S5j"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = ... # remember to set 'handle_unknown' to 'ignore'!\n",
    "enc.fit(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XOEk9q9Y-S5l",
    "outputId": "3d4939ef-6c7d-4a95-c33c-414bd75fa4c8"
   },
   "outputs": [],
   "source": [
    "enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8O0xnTUV-S5m",
    "outputId": "c5765108-b8f0-42b0-a38a-57dddf4e142e"
   },
   "outputs": [],
   "source": [
    "enc.transform(...) # As you can see, the result is a sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GppvZHNy-S5o",
    "outputId": "8f8daa97-9b18-4652-9294-b4056567971e"
   },
   "outputs": [],
   "source": [
    "print('Shape of encoded:', enc.transform(train_df[['initial']]).todense().shape)\n",
    "enc.transform(train_df[['initial']]).todense() # take a look a it, it's a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.6 Normalization/归一化\n",
    "- **TODO 2.6:** 对 `Fare` 这一列进行归一化\n",
    "- [Scikit Standard Scaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = ...\n",
    "ss.fit(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.transform(...)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[['Fare']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0GzPqWqJ-S5p"
   },
   "source": [
    "### 2.2.7 Pipeline & ColumnTransformer\n",
    "- **TODO 2.7:** 将 one-hot encoding 和其他的 feature transform 都塞进 Pipeline 里\n",
    "- [Scikit Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)\n",
    "- [ColumnTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nvzhLtUA-S5p",
    "outputId": "8705b401-b9b5-46e3-b736-2ebfe6b129ca",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.head(2) # 这里的 Survived 是不需要的！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_df.drop(columns = ['Survived']), train_df.Survived.values\n",
    "X_test = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5X1AOj7V-S5p"
   },
   "outputs": [],
   "source": [
    "# handle application features\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Your Code Starts Here\n",
    "num_feat = [...]\n",
    "num_trans = Pipeline(\n",
    "    steps = [\n",
    "        ('scalar', StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "one_hot = OneHotEncoder(handle_unknown = 'ignore')\n",
    "cat_feat = [...]\n",
    "cat_trans = Pipeline(\n",
    "    steps = [\n",
    "        ('onehot', one_hot)\n",
    "    ]\n",
    ")\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('num', ..., ...),\n",
    "        ('cat', ..., ...)\n",
    "    ]\n",
    ")\n",
    "ct = ct.fit(X_train)\n",
    "# Your Code Ends Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P0kMKUDn-S5s"
   },
   "outputs": [],
   "source": [
    "X_train = ct.transform(X_train)\n",
    "X_test = ct.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vAcHmg63-S51",
    "outputId": "064d2d73-0ee1-4051-baf0-6f63c34414d9"
   },
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "efCY-hCpU46x"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lL2IVhvbMFWT"
   },
   "source": [
    "## 2.3. Model Selection\n",
    "- 在这一部分，我们将训练并挑选最合适的模型。在开始之前，我们需要定义我们评判模型好坏的标准（Metric）。注意这和 Loss function 并不一样：\n",
    "    - Loss function: 在 training 的过程中使用，取决于特定机器学习任务（e.g. 分类 / 回归）\n",
    "    - Metric: 在训练结束后使用，也取决于特定机器学习任务（e.g. 分类 / 回归）\n",
    "- 在这个部分，一共有 **1 个 TODO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7yMQUAgcWxfF"
   },
   "outputs": [],
   "source": [
    "#importing all the required ML packages\n",
    "from sklearn.linear_model import LogisticRegression #logistic regression\n",
    "from sklearn import svm #support vector Machine\n",
    "from sklearn.ensemble import RandomForestClassifier #Random Forest\n",
    "from sklearn.neighbors import KNeighborsClassifier #KNN\n",
    "from sklearn.tree import DecisionTreeClassifier #Decision Tree\n",
    "from sklearn.naive_bayes import GaussianNB #Naive bayes\n",
    "\n",
    "from sklearn.model_selection import train_test_split #training and testing data split\n",
    "from sklearn import metrics #accuracy measure\n",
    "from sklearn.metrics import confusion_matrix #for confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TkY_51ofMI0G"
   },
   "outputs": [],
   "source": [
    "X, y = X_train.copy(), y_train.copy() # Save the training set for future use\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z6dWEa-g-S56"
   },
   "source": [
    "- After creating validation set, we started to try some Sci-kit models for machine learning:\n",
    "    - `SVC ` (Support Vector Classification)\n",
    "    - `Logistic Regression`\n",
    "- For both of them, we will try various model parameters in order to find out the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dHgVO4rY-S56",
    "outputId": "4da0bde2-dc7e-4395-c031-21a0bec4b9e2"
   },
   "outputs": [],
   "source": [
    "# SVC model\n",
    "model = svm.SVC(kernel = 'rbf', C = 1, gamma = 0.1)\n",
    "model.fit(X_train, y_train)\n",
    "prediction1 = model.predict(X_val)\n",
    "print('Val acc for rbf SVM is ', metrics.accuracy_score(prediction1, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gzTFr0O0-S57"
   },
   "source": [
    "- **TODO 2.8**: \n",
    "    - Step 1 请阅读以下两个 documentation：[SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) 和 [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) 尤其注意 `C` 和 `gamma` 这两个超参数\n",
    "    - Step 2 从上面那个 cell 复制代码（SVM 模型）到下方的 cell 中，并尝试不同的 `C` 和 `gamma` 数值，观察模型的表现\n",
    "    - Step 3 尝试使用 Logistic Regression 来进行同样的分类 (try `C` = 0.1, 1, 10 and keep the one w/ best acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i3_Wnfvm-S57"
   },
   "outputs": [],
   "source": [
    "all_result = []\n",
    "# Your Code Starts Here - SVC\n",
    "...\n",
    "# Your Code Ends Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.DataFrame(all_result).sort_values(by = 'acc', ascending = False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bFBPUPva-S58"
   },
   "outputs": [],
   "source": [
    "all_result = []\n",
    "# Your Code Starts Here - Logistic Regression\n",
    "...\n",
    "# Your Code Ends Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KwaZSGiq-S58"
   },
   "outputs": [],
   "source": [
    "display(pd.DataFrame(all_result).sort_values(by = 'acc', ascending = False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HSLvuQVeMJmx"
   },
   "source": [
    "## 2.4. Model Testing\n",
    "- 在这个部分，我们将根据预先确定的 metric 来挑选最合适的数据集\n",
    "- 这个部分有 **1 个 TODO**\n",
    "- **TODO 2.9:** 从上面的模型和参数中选出一个最合适的模型以及它最好的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UCYrLg7iMIpC",
    "outputId": "59dfe73d-0897-4757-84f8-6e827716c2b8"
   },
   "outputs": [],
   "source": [
    "# Your Code Starts Here\n",
    "model = ... # Pick the best model\n",
    "# Your Code Ends Here\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "prediction = model.predict(X_test)\n",
    "\n",
    "test_passenger_id = pd.read_csv('data/test.csv').PassengerId.values\n",
    "test['PassengerId'] = test_passenger_id\n",
    "test['Survived'] = prediction.astype('int')\n",
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jVVD-zQjMMDX"
   },
   "source": [
    "## 2.5. Export Prediction & Submission\n",
    "- Submit to this website: https://www.kaggle.com/c/titanic/submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dyBWZkO7Mk8N",
    "outputId": "f4a481b7-c92b-4f02-b583-01ad44682b69"
   },
   "outputs": [],
   "source": [
    "# Make sure your submission looks like this\n",
    "pd.read_csv('data/gender_submission.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TRHSd0lcMk0g"
   },
   "outputs": [],
   "source": [
    "test[['PassengerId', 'Survived']].to_csv('data/submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['PassengerId', 'Survived']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bJhELOZBMQwz"
   },
   "source": [
    "# The End."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2_Intro_to_ML.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
